{"nbformat_minor": 0, "cells": [{"source": "/** Verify that the kernel is up and running */\nprintln(s\"Kernel is up and running\")", "cell_type": "code", "execution_count": 1, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Kernel is up and running\n"}], "metadata": {"collapsed": false}}, {"source": "/* specify schema for clickstream data */\nimport org.apache.spark.sql.types._\n\nval clickdataSchema = StructType(Array(\n      StructField(\"eventId\", LongType, false),\n      StructField(\"eventType\", StringType, false),\n      StructField(\"timestamp\", StringType, false),\n      StructField(\"ipaddress\", StringType, false),\n      StructField(\"sessionId\", StringType, false),\n      StructField(\"userId\", StringType, false),\n      StructField(\"pageUrl\", StringType, false),\n      StructField(\"browser\", StringType, false)))", "cell_type": "code", "execution_count": 2, "outputs": [], "metadata": {"collapsed": true}}, {"source": "/** BLUSpark imports and connection information */\nimport sys.process._\nimport scala.concurrent.{Await, Future}\nimport scala.concurrent.duration.Duration\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types._\nimport com.ibm.bluspark.catalog.TableSchema\nimport com.ibm.bluspark.oltp.OLTPContext\nimport com.ibm.bluspark.example.DataGenerator\nimport com.ibm.bluspark.common.ConfigurationReader\nimport com.ibm.bluspark.oltp.InsertResult\nimport com.ibm.bluspark.example.BluSparkUtil\nConfigurationReader.setConnectionEndpoints(\"xx.xx.xx.xx:5555\")", "cell_type": "code", "execution_count": 3, "outputs": [], "metadata": {"collapsed": true}}, {"source": "/** Run this cell if you need to CREATE the database.  */\nval oltpContext = OLTPContext.createDatabase(\"CLICKDB\")\nval error =  oltpContext.openDatabase()\nerror.map(e => sys.error(e.toString))", "cell_type": "code", "execution_count": 4, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "None"}, "execution_count": 4, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "/** Define Table schema for clickstream data */\nval clickStreamSchema = TableSchema(\"ClickStreamTable\", clickdataSchema, Array(\"eventId\"),Array(\"eventId\"))", "cell_type": "code", "execution_count": 5, "outputs": [], "metadata": {"collapsed": false}}, {"source": "/** Create the table - skip if table is already created */\nvar res = oltpContext.dropTable(clickStreamSchema.tableName)\nvar res = oltpContext.createTable(clickStreamSchema)\nif (res.isDefined) {\n  println(s\"Error while creating table ${clickStreamSchema.tableName}\\n: ${res.get}\")\n} else {\n  println(s\"Table ${clickStreamSchema.tableName} successfully created.\")\n}", "cell_type": "code", "execution_count": 6, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Table ClickStreamTable successfully created.\n"}], "metadata": {"collapsed": false}}, {"source": "val clickstreamTable = oltpContext.getTable(\"ClickStreamTable\")", "cell_type": "code", "execution_count": 7, "outputs": [], "metadata": {"collapsed": true}}, {"source": "/* initialize spark session*/\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.DataFrameReader\n\nval spark: SparkSession = SparkSession.\n    builder().\n    getOrCreate()\n\nimport spark.implicits._\n\nval clickStreamDF = spark.read.option(\"header\", \"true\").option(\"inferSchema\", false).schema(clickdataSchema).csv(\"click_stream_dataV52.csv\")\n\nclickStreamDF.show(5)", "cell_type": "code", "execution_count": 8, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----------+---------+----------+------------+-----------------+------+--------------------+-------+\n|    eventId|eventType| timestamp|   ipaddress|        sessionId|userId|             pageUrl|browser|\n+-----------+---------+----------+------------+-----------------+------+--------------------+-------+\n|20170522901| pageView|1496311260|169.34.56.78|y20170522a4499u21|ceaton|http://www.cybers...| Chrome|\n|20170522902| pageView|1496311320|169.34.56.78|y20170522a4499u21|ceaton|http://www.cybers...| Chrome|\n|20170522903| pageView|1496311440|169.34.56.78|y20170522a4499u21|ceaton|http://www.cybers...| Chrome|\n|20170522904| pageView|1496311500|169.34.56.78|y20170522a4499u21|ceaton|http://www.cybers...| Chrome|\n|20170522905| pageView|1496311560|169.34.56.78|y20170522a4499u21|ceaton|http://www.cybers...| Chrome|\n+-----------+---------+----------+------------+-----------------+------+--------------------+-------+\nonly showing top 5 rows\n\n"}], "metadata": {"collapsed": false}}, {"source": "/** Iteratively Insert rows in batch */\nimport collection.JavaConverters._\n\nval iter = clickStreamDF.toLocalIterator() \nval error = oltpContext.batchInsert(clickstreamTable, iter.asScala)\nif (error.isDefined) {\n    System.err.println(error)\n}\nprintln(s\"\"\"Ingest completed successfully\"\"\")", "cell_type": "code", "execution_count": 9, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Ingest completed successfully\n"}], "metadata": {"collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Apache Toree - Scala", "name": "apache_toree_scala", "language": "scala"}, "language_info": {"file_extension": ".scala", "version": "2.11.8", "name": "scala"}}}
